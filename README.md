# AI Data Governance & Compliance Mapping Framework (India)

## Project Overview

****A collection of guidelines introduces how policies can shape real-world data handling for generative AI services available to the public in India****. While focused on implementation, it bridges rules with practical workflows through structured oversight methods. Each step reflects local context, adapting governance ideas into actionable routines. Instead of theoretical models, the approach emphasizes usable tools shaped by regulatory needs. From design to deployment, accountability remains embedded within operational layers

Starting with India’s laws, the work turns rules into clear steps tied to each stage of a product's life. Because real-world use changes over time, risks are mapped along that timeline. Controls fit how decisions get made inside organizations. Compliance tasks follow function, not just formality. What results is action grounded in structure.

A small yet full research output, shaped by standards common in AI ethics placements and governance settings - compact without missing key parts. Though brief, it meets what such programs usually require, fitting within norms of structured inquiry while staying self-contained.

---

## Problem Statement

Through conversations with users, public generative AI gathers information nonstop. While people ask questions or request outputs, new data forms constantly. As inputs arrive, the system logs them alongside generated replies. Because interactions happen repeatedly, accumulation occurs without pause. Even minor exchanges contribute to growing datasets over time. With each session, material builds up across platforms. Since access remains open, collection proceeds without breaks

 This brings about intricate issues in how decisions are made, particularly when it comes to:
 

 1. Personal data protection in India under the 2023 law
 2. **Security duties and intermediary roles under the Information Technology Act 2000**
 3. Copyright Risks in AI Training and Outputs Under the **Copyright Act    1957**
 4. Emerging concerns around misinformation and synthetic content

Right now, Indian creators and users of artificial intelligence do not have straightforward direction tied to each stage of development showing how rules shape actual system setup and daily function.

---

## Project Objective

To design a **safety-by-design AI data governance framework** that:

1. Maps Indian regulations to the AI data lifecycle  
2. Identifies data-related risks at each lifecycle stage  
3. Translates risks into implementable governance controls  
4. Provides a functional checklist usable by AI teams  
5. Supports policy-grade documentation and future research outputs  

---

## Scope

- **AI System Type**: Public-facing generative AI systems (chatbots, writing assistants, general-purpose AI tools)  
- **Geographic Scope**: India  
- **Regulatory Focus**:
  - Digital Personal Data Protection Act, 2023  
  - Information Technology Act, 2000 and related rules  
  - Indian Copyright Act, 1957  
  - Emerging AI and deepfake guidelines  

### Explicit Exclusions
- Military or surveillance AI systems  
- Physical AI systems (robotics, IoT)  
- Offline or non-user-facing models  
- Non-Indian regulatory regimes  

---

## Repository Structure

```
.
├── Scope.md
├── lifecycle/
│   └── ai_data_lifecycle.md
├── governance/
│   ├── regulation_risk_mapping.md
│   ├── risk_control_mapping.md
│   └── functional_governance_checklist.md
└── README.md
```

---

## Key Artifacts

1. **AI Data Lifecycle Framework**
Starting with how information is gathered, this framework outlines steps for managing public generative AI through its entire existence. Moving forward, oversight continues until systems are retired. Along the way, each phase ties into broader accountability structures. Before shutdown occurs, evaluations help assess long-term impacts. Throughout, rules adapt based on real-world use patterns. Ending only when operations cease fully, the process ensures responsibility does not stop early.

2. **Regulation Shapes How Risks Are Mapped**
Maps Indian legal obligations to **concrete data risks across lifecycle** stages.

3. **Risk and Governance Control Links**
Turning known risks into practical safeguards follows naturally once clarity emerges. Technical steps come together alongside updated policies when guidance shapes action. Procedures adapt as new conditions unfold across teams. Legal frameworks shift under steady review. Implementation grows out of careful planning paired with real-world testing.

4. **Functional Governance Checklist**
A practical guide helps teams evaluate how well they meet requirements. Step-by-step steps support both creators and users during review. Following structured points improves clarity on preparedness. Each item focuses attention where it matters most. Clarity emerges through consistent evaluation methods.

---

## Methodology

- Lifecycle-based AI governance analysis  
- Legal interpretation grounded in Indian statutes  
- Risk identification focused on real-world generative AI practices  
- Safety-by-design and accountability principles  

The project emphasizes **operationalization of law**, not abstract policy discussion.

---

## Intended Use

- Reference framework for AI developers and deployers in India  
- Input for policy briefs, research papers, or internship deliverables  
- Foundation for extended sector-specific AI governance studies  

---

## Status

This repository represents a **completed mini research project**.  
Future extensions may include:
- Sectoral case studies (healthcare, finance, education)  
- Comparative analysis with EU AI Act or OECD frameworks  
- Empirical evaluation of governance practices  

---

## Author
Sahil Raj

Prepared as part of an independent research exercise aligned with responsible AI and data governance internship expectations in India.
