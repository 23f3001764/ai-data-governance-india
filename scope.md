

# AI Data Governance and Compliance in India


## Project Title

**Data Governance in Public Generative AI Systems Across Their Lifespan in India**



## AI System Type

**Public-facing generative AI** sits at the heart of this study. Among these are chatbots, broad-scale language models, and tools that produce material through artificial intelligence. Interaction happens straight from system to user - no middle layer involved. What people submit gets used right away within those exchanges.



Examples include:

- AI chatbots

- AI writing assistants

- AI-powered customer support systems

- General Purpose Generative AI Tools

Interaction shapes these systems first, drawing on both personal and general information people supply during exchanges. User inputs feed into responses, often stored within dialogue logs or ratings. Processing follows naturally, guided by what individuals share across sessions. Data flows continuously, shaped less by design than by ongoing engagement. Each exchange adds depth, building responsiveness over time.
This core analysis leaves out predictive machine learning systems like credit scoring and risk models.

## Primary Sector

Most attention goes to widely accessible online platforms using generative AI across India. Such tools aim at mass audiences through everyday apps and digital services. While built for many users, they operate within public networks. Their reach grows alongside integration into routine tech experiences.

These setups keep users involved nonstop, handle actions instantly, yet gather massive amounts of information - raising concerns about oversight, personal data control, and responsibility. Uses in areas like medicine or banking might come up later as supporting examples; however, they do not shape the core aim here.



## Geographic and Regulatory Scope

This study centers only on India's rules, mainly looking at:

 - Digital Personal Data Protection Act 2023 and DPDP Rules 2025
 - Information Technology Act 2000 and Related Rules 
 - Indian Copyright Act 1957 (as applied to AI training and AI-generated outputs)  
 - Emerging AI governance and deepfake-related guidelines

## AI Data Lifecycle Coverage

The way rules and oversight fit into every phase of an AI data cycle forms the core of this study
The project examines how regulatory and governance requirements apply across each stage of the AI data lifecycle:

1. Data Collection  
2. Data Labeling and Preprocessing  
3. Model Training and Fine-Tuning  
4. Deployment and User Interaction  
5. Decommissioning, Data Retention, and Deletion  




## Key Exclusions

  

- Physical AI Systems Like Robotics And IoT

- Military and Surveillance AI Systems

- Purely offline or non-user-facing AI models

- Other countries’ rules appear here only when needed for contrast.

- Regulatory systems outside India stay out of focus throughout

## Purpose of Scope Definition

This scope definition ensures a focused and practical governance analysis rooted in India’s legal framework. It supports the project objective of translating high-level policy and regulatory obligations into concrete functional requirements, governance controls, and compliance mechanisms across the AI system lifecycle. The emphasis is on operationalizing legal duties into measurable and implementable compliance actions at each stage of system development and deployment.

## Core Research Questions

1. How do Indian data protection and copyright laws apply across each stage of the AI data lifecycle in public generative AI systems?
2. What data-related risks emerge from user interaction and continuous data generation in public-facing AI tools?
3. How can legal obligations under Indian law be translated into concrete governance controls and safety-by-design mechanisms?
4. What gaps exist between current AI data practices and regulatory expectations in India?
